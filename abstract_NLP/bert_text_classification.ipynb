{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict inclusion and exclusion of abstracts for Ceres2030 Team 6.\n",
    "\n",
    "This document compares three natural language processing (NLP) approaches to binary classification:\n",
    "- BERT\n",
    "- Naive Bayes\n",
    "- Support Vector Machines (SVM)\n",
    "\n",
    "We find each method is better than our team's present inter-rater reliability of 80%. Inter-rater reliability is a measure of the percent of conflicts reviewers had compared total abstracts double reviewed.\n",
    "\n",
    "Here is a summary of our findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "image/png": {
       "width": 400
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='compare_model.png', width=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1013 16:23:21.525433 140147688564544 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from datetime import datetime\n",
    "from bert_text import run_on_dfs\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "import bert\n",
    "from bert import run_classifier\n",
    "from bert import optimization\n",
    "from bert import tokenization\n",
    "# !pip install bert-tensorflow\n",
    "tf.logging.set_verbosity(tf.logging.FATAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv('./data/Team_6.csv')\n",
    "selected = pd.read_csv('./data/review_59500_select_csv_20190925102202.csv')\n",
    "irrelevant = pd.read_csv('./data/review_59500_irrelevant_csv_20190925102123.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up train/test dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.357191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment\n",
       "count  1500.000000\n",
       "mean      0.150000\n",
       "std       0.357191\n",
       "min       0.000000\n",
       "25%       0.000000\n",
       "50%       0.000000\n",
       "75%       0.000000\n",
       "max       1.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selected['text'] = selected['Title'] + ' ' + selected['Abstract']\n",
    "selected['text'] = selected['Abstract'].str.replace('Abstract: ', '')\n",
    "selected['text'] = selected['text'].str.split('#',  n = 1, expand = True)\n",
    "selected['sentiment'] = 1\n",
    "\n",
    "# irrelevant['text'] = irrelevant['Title'] + ' ' + irrelevant['Abstract']\n",
    "irrelevant['text'] = irrelevant['Abstract'].str.replace('Abstract: ', '')\n",
    "irrelevant['text'] = irrelevant['text'].str.split('#',  n = 1, expand = True)\n",
    "irrelevant['sentiment'] = 0\n",
    "\n",
    "df = pd.concat([\n",
    "    selected.loc[:, ['text', 'sentiment']],\n",
    "    irrelevant.loc[:, ['text', 'sentiment']],\n",
    "])\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into training and testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1125.000000</td>\n",
       "      <td>375.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.152000</td>\n",
       "      <td>0.144000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.359181</td>\n",
       "      <td>0.351559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             train        test\n",
       "count  1125.000000  375.000000\n",
       "mean      0.152000    0.144000\n",
       "std       0.359181    0.351559\n",
       "min       0.000000    0.000000\n",
       "25%       0.000000    0.000000\n",
       "50%       0.000000    0.000000\n",
       "75%       0.000000    0.000000\n",
       "max       1.000000    1.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = train_test_split(df)\n",
    "train = train.sample(len(train))\n",
    "t = pd.concat([train.describe(), test.describe()], axis = 1)\n",
    "t.columns = ['train', 'test']\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up predict dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinny_ricciardi/virtenvs/ceres_36/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "all_data['check'] = all_data['title'].isin(irrelevant['Title']) | \\\n",
    "                    all_data['title'].isin(selected['Title'])\n",
    "\n",
    "to_predict = all_data.query('check == False')\n",
    "\n",
    "# if abstract is blank, replace with title\n",
    "to_predict['abstracts_new'] = np.where(to_predict['abstract'].isna(), \n",
    "                                       to_predict['title'], \n",
    "                                       to_predict['abstract'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A high-level approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zwYoyLfLQI-t"
   },
   "source": [
    "Base code heavily borrowed from [this Google Colab Notebook](https://colab.research.google.com/github/google-research/bert/blob/master/predicting_movie_reviews_with_bert_on_tf_hub.ipynb).\n",
    "\n",
    "Please refer to [this Medium Article](https://medium.com/@wshuyi/how-to-do-text-binary-classification-with-bert-f1348a25d905) for detailed information.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qCoK42AGIXsS"
   },
   "outputs": [],
   "source": [
    "myparam = {\n",
    "    'DATA_COLUMN': 'text',\n",
    "    'LABEL_COLUMN': 'sentiment',\n",
    "    'LEARNING_RATE': 2e-5,\n",
    "    'MAX_SEQ_LENGTH': 512,\n",
    "    'NUM_TRAIN_EPOCHS': 10,\n",
    "    'bert_model_hub': 'https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YoOVNBr7IsjS",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "result, estimator = run_on_dfs(train, test, **myparam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kaZMjQ0cIw9y",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auc': 0.9027345,\n",
       " 'eval_accuracy': 0.96533334,\n",
       " 'f1_score': 0.87128705,\n",
       " 'false_negatives': 10.0,\n",
       " 'false_positives': 3.0,\n",
       " 'loss': 0.18589474,\n",
       " 'precision': 0.9361702,\n",
       " 'recall': 0.8148148,\n",
       " 'true_negatives': 318.0,\n",
       " 'true_positives': 44.0,\n",
       " 'global_step': 351}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_1 = result\n",
    "bert_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPrediction(in_sentences):\n",
    "\n",
    "    labels = ['Exclude', 'Include']\n",
    "    \n",
    "    input_examples = [run_classifier.InputExample(\n",
    "      guid='', text_a = x, text_b = None, label = 0) for x in in_sentences] # here, \"\" is just a dummy label\n",
    "    \n",
    "    input_features = run_classifier.convert_examples_to_features(\n",
    "      input_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "    \n",
    "    predict_input_fn = run_classifier.input_fn_builder(\n",
    "      features=input_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=False)\n",
    "    \n",
    "    predictions = estimator.predict(predict_input_fn)\n",
    "    \n",
    "    out = [(sentence, prediction['probabilities'], labels[prediction['labels']]) for sentence, prediction in zip(in_sentences, predictions)]\n",
    "#     out = []\n",
    "#     sent = []\n",
    "#     i = 0\n",
    "#     for sentence, prediction in zip(in_sentences, predictions):\n",
    "#         out.append(prediction)    \n",
    "#         sent.append(sentence)\n",
    "    \n",
    "    return(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_list is the list of labels, i.e. True, False or 0, 1 or 'dog', 'cat'\n",
    "label_list = [0, 1]\n",
    "MAX_SEQ_LENGTH = myparam['MAX_SEQ_LENGTH']\n",
    "\n",
    "# This is a path to an uncased (all lowercase) version of BERT\n",
    "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "\n",
    "def create_tokenizer_from_hub_module():\n",
    "  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "  with tf.Graph().as_default():\n",
    "    bert_module = hub.Module(BERT_MODEL_HUB)\n",
    "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "    with tf.Session() as sess:\n",
    "      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
    "                                            tokenization_info[\"do_lower_case\"]])\n",
    "      \n",
    "  return bert.tokenization.FullTokenizer(\n",
    "      vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "tokenizer = create_tokenizer_from_hub_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = getPrediction(test.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check that our predictions are working properly. Our self-computed evaluation accuracy is the same at `bet_text`'s evaluation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9653333333333334"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = test\n",
    "tmp['predictions'] = [predictions[i][2] for i in range(len(predictions))]\n",
    "tmp['predictions'] = np.where(tmp['predictions'] == 'Include', 1, 0)\n",
    "tmp['check'] = np.where(tmp['predictions'] == tmp['sentiment'], 1, 0)\n",
    "tmp['check'].sum() / len(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the remaining abstracts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # to_predict = to_predict.reset_index()\n",
    "# in_sentences = to_predict['abstracts_new'][:17000]\n",
    "\n",
    "# labels = ['Exclude', 'Include']\n",
    "\n",
    "# input_examples = [run_classifier.InputExample(\n",
    "#     guid='', \n",
    "#     text_a=x, \n",
    "#     text_b=None, \n",
    "#     label=0) for x in in_sentences] # here, \"\" is just a dummy label\n",
    "\n",
    "# input_features = run_classifier.convert_examples_to_features(\n",
    "#     input_examples, \n",
    "#     label_list, \n",
    "#     MAX_SEQ_LENGTH, \n",
    "#     tokenizer)\n",
    "\n",
    "# predict_input_fn = run_classifier.input_fn_builder(\n",
    "#     features=input_features, \n",
    "#     seq_length=MAX_SEQ_LENGTH, \n",
    "#     is_training=False, \n",
    "#     drop_remainder=False)\n",
    "\n",
    "# predictions = estimator.predict(predict_input_fn)\n",
    "\n",
    "# #     out = [(sentence, prediction['probabilities'], labels[prediction['labels']]) for sentence, prediction in zip(in_sentences, predictions)]\n",
    "# out = []\n",
    "# sent = []\n",
    "# i = 0\n",
    "# for sentence, prediction in zip(in_sentences, predictions):\n",
    "#     out.append(prediction)    \n",
    "#     sent.append(sentence)\n",
    "#     print(i)\n",
    "#     i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run in two batches since there was a index issue with both together (think it was a memory issue)\n",
    "out1 = getPrediction(to_predict['abstracts_new'][:17000])\n",
    "print('clear1')\n",
    "out2 = getPrediction(to_predict['abstracts_new'][17000:])\n",
    "print('clear2')\n",
    "o1 = [out1[i][2] for i in range(len(out1))]\n",
    "print('clear3')\n",
    "o2 = [out2[i][2] for i in range(len(out2))]\n",
    "print('clear4')\n",
    "# np.sum(o1) + np.sum(o2) + test['sentiment'].sum() + train['sentiment'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1575"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(o1, return_counts=True)[1][1] + \\\n",
    "np.unique(o2, return_counts=True)[1][1] + \\\n",
    "test['sentiment'].sum() + \\\n",
    "train['sentiment'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data to keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1568"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_predict['sentiment'] = o1 + o2\n",
    "out1 = to_predict.copy()\n",
    "out1 = out1.query(\"sentiment == 'Include'\")\n",
    "out1 = out1.loc[:, ['title', 'year', 'journal', 'author']]\n",
    "out1 = out1.loc[:, ['title', 'year', 'journal', 'author']]\n",
    "out2 = selected.copy()\n",
    "out2 = out2.loc[:, ['Title', 'Published Year', 'Journal', 'Authors']]\n",
    "out2.columns = out1.columns\n",
    "out = pd.concat([out1, out2], axis = 0)\n",
    "out = out.drop_duplicates()  # Note, there were 5 duplicates in the predict set and 2 in the training set. There was no leakage.\n",
    "len(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp1 = pd.merge(all_data, out, on=['title', 'year'], how='inner')\n",
    "tmp1 = tmp1.drop_duplicates(['title', 'year'])\n",
    "tmp2 = pd.merge(out, tmp1, on=['title', 'year'], how='outer', indicator=True)\n",
    "tmp3 = tmp2[tmp2['_merge']=='left_only']\n",
    "tmp2.to_csv('predicted_out.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A more detailed approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is essentially what the above was written on top of (the authors of bert_text wrote their package more streamlined than below, but we include here to let readers better understand how the underlying processes work). \n",
    "\n",
    "Base code for this section heavily borrowed/copied from [this Google Colab Notebook](https://colab.research.google.com/github/google-research/bert/blob/master/predicting_movie_reviews_with_bert_on_tf_hub.ipynb#scrollTo=fom_ff20gyy6).\n",
    "\n",
    "Note: this section's code is commented out since it is nearly the same as above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "We'll need to transform our data into a format BERT understands. This involves two steps. First, we create  `InputExample`'s using the constructor provided in the BERT library.\n",
    "\n",
    "- `text_a` is the text we want to classify, which in this case, is the `Request` field in our Dataframe. \n",
    "- `text_b` is used if we're training a model to understand the relationship between sentences (i.e. is `text_b` a translation of `text_a`? Is `text_b` an answer to the question asked by `text_a`?). This doesn't apply to our task, so we can leave `text_b` blank.\n",
    "- `label` is the label for our example, i.e. True, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_COLUMN = 'text'\n",
    "# LABEL_COLUMN = 'sentiment'\n",
    "# # label_list is the list of labels, i.e. True, False or 0, 1 or 'dog', 'cat'\n",
    "# label_list = [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use the InputExample class from BERT's run_classifier code to create examples from the data\n",
    "# train_InputExamples = train.apply(lambda x: bert.run_classifier.InputExample(\n",
    "#     guid=None, # Globally unique ID for bookkeeping, unused in this example\n",
    "#     text_a = x[DATA_COLUMN], \n",
    "#     text_b = None, \n",
    "#     label = x[LABEL_COLUMN]), axis = 1)\n",
    "\n",
    "# test_InputExamples = test.apply(lambda x: bert.run_classifier.InputExample(\n",
    "#     guid=None, \n",
    "#     text_a = x[DATA_COLUMN], \n",
    "#     text_b = None, \n",
    "#     label = x[LABEL_COLUMN]), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to preprocess our data so that it matches the data BERT was trained on. For this, we'll need to do a couple of things (but don't worry--this is also included in the Python library):\n",
    "\n",
    "\n",
    "1. Lowercase our text (if we're using a BERT lowercase model)\n",
    "2. Tokenize it (i.e. \"sally says hi\" -> [\"sally\", \"says\", \"hi\"])\n",
    "3. Break words into WordPieces (i.e. \"calling\" -> [\"call\", \"##ing\"])\n",
    "4. Map our words to indexes using a vocab file that BERT provides\n",
    "5. Add special \"CLS\" and \"SEP\" tokens (see the [readme](https://github.com/google-research/bert))\n",
    "6. Append \"index\" and \"segment\" tokens to each input (see the [BERT paper](https://arxiv.org/pdf/1810.04805.pdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, we'll need to load a vocabulary file and lowercasing information directly from the BERT tf hub module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This is a path to an uncased (all lowercase) version of BERT\n",
    "# BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "\n",
    "# def create_tokenizer_from_hub_module():\n",
    "#   \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "#   with tf.Graph().as_default():\n",
    "#     bert_module = hub.Module(BERT_MODEL_HUB)\n",
    "#     tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "#     with tf.Session() as sess:\n",
    "#       vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
    "#                                             tokenization_info[\"do_lower_case\"]])\n",
    "      \n",
    "#   return bert.tokenization.FullTokenizer(\n",
    "#       vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "# tokenizer = create_tokenizer_from_hub_module()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just learned that the BERT model we're using expects lowercase data (that's what stored in tokenization_info[\"do_lower_case\"]) and we also loaded BERT's vocab file. We also created a tokenizer, which breaks words into word pieces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.tokenize(\"This here's an example of using the BERT tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using our tokenizer, we'll call `run_classifier.convert_examples_to_features` on our InputExamples to convert them into features BERT understands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # We'll set sequences to be at most 512 tokens long.\n",
    "# MAX_SEQ_LENGTH = 512\n",
    "\n",
    "# # Convert our train and test features to InputFeatures that BERT understands.\n",
    "# train_features = bert.run_classifier.convert_examples_to_features(\n",
    "#     train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "\n",
    "# test_features = bert.run_classifier.convert_examples_to_features(\n",
    "#     test_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a model\n",
    "\n",
    "Now that we've prepared our data, let's focus on building a model. `create_model` does just this below. First, it loads the BERT tf hub module again (this time to extract the computation graph). Next, it creates a single new layer that will be trained to adapt BERT to our sentiment task (i.e. classifying whether an abstract is included or exclude). This strategy of using a mostly trained model is called [fine-tuning](http://wiki.fast.ai/index.php/Fine_tuning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_model(is_predicting, input_ids, input_mask, segment_ids, labels,\n",
    "#                  num_labels):\n",
    "#   \"\"\"Creates a classification model.\"\"\"\n",
    "\n",
    "#   bert_module = hub.Module(\n",
    "#       BERT_MODEL_HUB,\n",
    "#       trainable=True)\n",
    "#   bert_inputs = dict(\n",
    "#       input_ids=input_ids,\n",
    "#       input_mask=input_mask,\n",
    "#       segment_ids=segment_ids)\n",
    "#   bert_outputs = bert_module(\n",
    "#       inputs=bert_inputs,\n",
    "#       signature=\"tokens\",\n",
    "#       as_dict=True)\n",
    "\n",
    "#   # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
    "#   # Use \"sequence_outputs\" for token-level output.\n",
    "#   output_layer = bert_outputs[\"pooled_output\"]\n",
    "\n",
    "#   hidden_size = output_layer.shape[-1].value\n",
    "\n",
    "#   # Create our own layer to tune for our data.\n",
    "#   output_weights = tf.get_variable(\n",
    "#       \"output_weights\", [num_labels, hidden_size],\n",
    "#       initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "#   output_bias = tf.get_variable(\n",
    "#       \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
    "\n",
    "#   with tf.variable_scope(\"loss\"):\n",
    "\n",
    "#     # Dropout helps prevent overfitting\n",
    "#     output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
    "\n",
    "#     logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
    "#     logits = tf.nn.bias_add(logits, output_bias)\n",
    "#     log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "\n",
    "#     # Convert labels into one-hot encoding\n",
    "#     one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
    "\n",
    "#     predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
    "#     # If we're predicting, we want predicted labels and the probabiltiies.\n",
    "#     if is_predicting:\n",
    "#       return (predicted_labels, log_probs)\n",
    "\n",
    "#     # If we're train/eval, compute loss between predicted and actual label\n",
    "#     per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
    "#     loss = tf.reduce_mean(per_example_loss)\n",
    "    \n",
    "#     return (loss, predicted_labels, log_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll wrap our model function in a `model_fn_builder` function that adapts our model to work for training, evaluation, and prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model_fn_builder actually creates our model function\n",
    "# # using the passed parameters for num_labels, learning_rate, etc.\n",
    "# def model_fn_builder(num_labels, learning_rate, num_train_steps,\n",
    "#                      num_warmup_steps):\n",
    "#   \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
    "#   def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
    "#     \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
    "\n",
    "#     input_ids = features[\"input_ids\"]\n",
    "#     input_mask = features[\"input_mask\"]\n",
    "#     segment_ids = features[\"segment_ids\"]\n",
    "#     label_ids = features[\"label_ids\"]\n",
    "\n",
    "#     is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
    "    \n",
    "#     # TRAIN and EVAL\n",
    "#     if not is_predicting:\n",
    "\n",
    "#       (loss, predicted_labels, log_probs) = create_model(\n",
    "#         is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "\n",
    "#       train_op = bert.optimization.create_optimizer(\n",
    "#           loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
    "\n",
    "#       # Calculate evaluation metrics. \n",
    "#       def metric_fn(label_ids, predicted_labels):\n",
    "#         accuracy = tf.metrics.accuracy(\n",
    "#             label_ids, \n",
    "#             predicted_labels)\n",
    "#         f1_score = tf.contrib.metrics.f1_score(\n",
    "#             label_ids,\n",
    "#             predicted_labels)\n",
    "#         auc = tf.metrics.auc(\n",
    "#             label_ids,\n",
    "#             predicted_labels)\n",
    "#         recall = tf.metrics.recall(\n",
    "#             label_ids,\n",
    "#             predicted_labels)\n",
    "#         precision = tf.metrics.precision(\n",
    "#             label_ids,\n",
    "#             predicted_labels) \n",
    "#         true_pos = tf.metrics.true_positives(\n",
    "#             label_ids,\n",
    "#             predicted_labels)\n",
    "#         true_neg = tf.metrics.true_negatives(\n",
    "#             label_ids,\n",
    "#             predicted_labels)   \n",
    "#         false_pos = tf.metrics.false_positives(\n",
    "#             label_ids,\n",
    "#             predicted_labels)  \n",
    "#         false_neg = tf.metrics.false_negatives(\n",
    "#             label_ids,\n",
    "#             predicted_labels)\n",
    "#         return {\n",
    "#             \"eval_accuracy\": accuracy,\n",
    "#             \"f1_score\": f1_score,\n",
    "#             \"auc\": auc,\n",
    "#             \"precision\": precision,\n",
    "#             \"recall\": recall,\n",
    "#             \"true_positives\": true_pos,\n",
    "#             \"true_negatives\": true_neg,\n",
    "#             \"false_positives\": false_pos,\n",
    "#             \"false_negatives\": false_neg\n",
    "#         }\n",
    "\n",
    "#       eval_metrics = metric_fn(label_ids, predicted_labels)\n",
    "\n",
    "#       if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "#         return tf.estimator.EstimatorSpec(mode=mode,\n",
    "#           loss=loss,\n",
    "#           train_op=train_op)\n",
    "#       else:\n",
    "#           return tf.estimator.EstimatorSpec(mode=mode,\n",
    "#             loss=loss,\n",
    "#             eval_metric_ops=eval_metrics)\n",
    "#     else:\n",
    "#       (predicted_labels, log_probs) = create_model(\n",
    "#         is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "\n",
    "#       predictions = {\n",
    "#           'probabilities': log_probs,\n",
    "#           'labels': predicted_labels\n",
    "#       }\n",
    "#       return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "\n",
    "#   # Return the actual model function in the closure\n",
    "#   return model_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compute train and warmup steps from batch size\n",
    "# # These hyperparameters are copied from this colab notebook (https://colab.sandbox.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb)\n",
    "# BATCH_SIZE = 32\n",
    "# LEARNING_RATE = 2e-5\n",
    "# NUM_TRAIN_EPOCHS = 10.\n",
    "# # Warmup is a period of time where the learning rate \n",
    "# # is small and gradually increases--usually helps training.\n",
    "# WARMUP_PROPORTION = 0.1\n",
    "# # Model configs\n",
    "# SAVE_CHECKPOINTS_STEPS = 500\n",
    "# SAVE_SUMMARY_STEPS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compute # train and warmup steps from batch size\n",
    "# num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
    "# num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Specify output directory and number of checkpoint steps to save\n",
    "# run_config = tf.estimator.RunConfig(\n",
    "# #     model_dir=OUTPUT_DIR,\n",
    "#     save_summary_steps=SAVE_SUMMARY_STEPS,\n",
    "#     save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_fn = model_fn_builder(\n",
    "#   num_labels=len(label_list),\n",
    "#   learning_rate=LEARNING_RATE,\n",
    "#   num_train_steps=num_train_steps,\n",
    "#   num_warmup_steps=num_warmup_steps)\n",
    "\n",
    "# estimator = tf.estimator.Estimator(\n",
    "#   model_fn=model_fn,\n",
    "#   config=run_config,\n",
    "#   params={\"batch_size\": BATCH_SIZE})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create an input builder function that takes our training feature set (`train_features`) and produces a generator. This is a pretty standard design pattern for working with Tensorflow [Estimators](https://www.tensorflow.org/guide/estimators)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create an input function for training. drop_remainder = True for using TPUs.\n",
    "# train_input_fn = bert.run_classifier.input_fn_builder(\n",
    "#     features=train_features,\n",
    "#     seq_length=MAX_SEQ_LENGTH,\n",
    "#     is_training=True,\n",
    "#     drop_remainder=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'Beginning Training!')\n",
    "# current_time = datetime.now()\n",
    "# estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
    "# print(\"Training took time \", datetime.now() - current_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result will be similar to the streamlined approach, but not identical because we didn't set a seed for the randomization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_input_fn = run_classifier.input_fn_builder(\n",
    "#     features=test_features,\n",
    "#     seq_length=MAX_SEQ_LENGTH,\n",
    "#     is_training=False,\n",
    "#     drop_remainder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert_2 = estimator.evaluate(input_fn=test_input_fn, steps=None)\n",
    "# bert_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getPrediction(in_sentences):\n",
    "#   labels = ['Exclude', 'Include']\n",
    "#   input_examples = [run_classifier.InputExample(\n",
    "#       guid='', text_a = x, text_b = None, label = 0) for x in in_sentences] # here, \"\" is just a dummy label\n",
    "#   input_features = run_classifier.convert_examples_to_features(\n",
    "#       input_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "#   predict_input_fn = run_classifier.input_fn_builder(\n",
    "#       features=input_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=False)\n",
    "#   predictions = estimator.predict(predict_input_fn)\n",
    "#   return [(sentence, prediction['probabilities'], labels[prediction['labels']]) for sentence, prediction in zip(in_sentences, predictions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_sentences = [\n",
    "# \"Emerging trends of a changing and increasingly variable climate have introduced new livelihood challenges in rain-fed smallholder agricultural systems that predominate in Sub-Saharan Africa (SSA). The capacity of local farming communities and their institutions to respond to the new and emerging impacts of climate change is often constrained by lack of access to information and improved technologies, as well as poor support mechanisms to promote assimilation of new knowledge. This threatens to heighten vulnerability of the majority of SSA's rural communities who are already facing severe problems of food insecurity and a declining soil resource base. In this paper we use two case studies from Wenchi district in Ghana and Makoni in Zimbabwe to communicate how participatory action research (PAR) methodology, characterised by iterative planning-action-reflection cycles, was coupled with a new concept of field-based farmer learning centres to build adaptive capacity of smallholder farmers to climate change. The study was part of a University of Zimbabwe-led project supported under the Climate Change Adaptation in Africa (CCAA) programme to explore the state of resilience in African smallholder farming. The PAR and learning centre processes enabled communities, local leaders, and extension agents and researchers to establish the, hither to, imperceptible link between poor soil fertility and rising institutional challenges within communities. Institutional conflicts related to land tenure and sharecropping arrangements between migrant farmers and native landowners were addressed in Ghana, while local institutions supporting traditional social safety net mechanisms were revitalized in Zimbabwe. In both cases, it was apparent that farmers faced multiple stresses, at the core of which were poor and declining soil fertility and weakening local institutions. The worsening rainfall distribution and increasing cases of drought are broadening the scope for vulnerability, often driving competing claims and conflicts. PAR was successfully used as an entry point, empowering communities to self-mobilize and self-organize to co-learn and experiment with integrated soil fertility management (ISFM) technologies and other improved farming practices. They realised opportunities for achieving high crop yields and generate surpluses in good years. Strengthening local institutional capacity to revitalise community safety nets proved an essential ingredient for enhancing adaptive capacity of smallholders to climatic shocks. The PAR process was a major driver of effective partnerships among community members, extension, policy makers and researchers, but ensuing success generated a new set of social challenges that could not be addressed within the short timescale of the project. We conclude that PAR was a suitable mechanism for supporting self-organization and co-learning processes among smallholder farmers and their service providers, enabling them to use ISFM technologies and strengthen their local institutions around natural resource management. This revealed the scope for building adaptive capacity of these communities against climate change and variability.\",\n",
    "# \"Farmers in Southern Africa are already experiencing changes to their climate that are different in magnitude to what they have experienced in the past. Some of these changes, particularly higher temperatures and greater rainfall intensity, are consistent with what scientists expect to happen as the Earth's climate warms due to emissions of carbon dioxide and other greenhouse gases. These changes are adding to other political, economic and environmental stresses on their livelihoods. This report comprises new field research by Oxfam and Kulima Integrated Development Solutions with over 200 farmers in five countries of Southern Africa. It finds considerable agreement between farmers across countries that they are observing changes in climate. The perceptions of farmers largely find backing in the meteorological data. Ongoing climate change, bringing increasing temperatures and further changes to precipitation patterns, is projected to make food production more difficult. Recent scientific research compiling the results of many thousands of field tests on maize, in particular, demonstrate the serious effects of temperature increases and changes in moisture (Lobell et al, 2011a). Climate change is likely to reduce yields and increase food prices, with serious effects on both farmers and consumers. Farmers are already actively experimenting and changing agricultural practices and pursuing ways to diversify livelihoods in light of both the new changes to their climate and other multiple stresses. In some cases, these changes can be considered actual or potential successes in adapting to climate change; in other cases they may be simply coping, and other strategies can be considered maladaptation, particularly where they create environmental degradation. Furthermore, whereas large-scale farmers, in the main, have access to the resources needed to adapt, small-scale farmers face major obstacles. These obstacles may not only prevent adaptation but also lead farmers into maladaptation, for want of other choices. Major new resources must be raised from domestic, regional and international levels to focus on and build the adaptive capacity of small-scale farmers and sustain levels of food production into the future.\",\n",
    "# \"In marginal areas, including saline lands, patchy plant stands often result from poor and uneven germination of the crop. The technique of 'on-farm' seed priming, where the seed is soaked in water, usually overnight, before being surface dried and then sown, has been shown to improve plant stands and provide benefits in terms of earlier maturity, reduced disease and increased yields in a range of crops in rainfed areas in Africa, India, Nepal and Bangladesh, as well as in irrigated crops grown on normal soils in India. This paper describes trials to assess the technique for maize, wheat and chickpea grown in saline lands in the North West Frontier Province of Pakistan, using a mixture of on-farm and farmer-participatory trials. Initial studies on germination carried out in laboratory conditions are also reported. In almost all the trials, priming had a significant positive effect on yields: the only trials in which it was not successful were those on dense saline-sodic soils, and possible reasons for this are discussed. Feedback from the farmers indicated that they had very favourable impressions of the technique.\",\n",
    "# \"This chapter focuses on the N contribution by promiscuous soyabean in an attempt to develop sustainable cropping systems in the moist savanna in West Africa. There is, however, a dearth of reliable estimates of N fixation by these promiscuous soyabean and hardly any quantitative information is available on their residual N benefits to subsequent cereal crops grown in the southern Guinea savanna (SGS) zone. The actual amount of N fixed by promiscuous soyabean varied between 38 and 126 kg N ha. Assuming that only seed of soyabean are removed from the plots, it is estimated that the net N accrual to soil ranges between -8 kg N ha and +47 kg N ha depending on the soyabean lines. Residual soyabean N values between 10 and 24 kg N ha representing 14 to 36% of the maize total N were obtained in maize grown after soyabean. Although traditionally the increases in cereal yield following legume cultivation are attributed to greater N accumulation, our data show that the relative increase in maize N following soyabean was smaller than the relative increase in dry matter yield. Hence, the increased yields of maize following soyabean were not due entirely to the carry-over of N from the soyabean residue and to the soil N-conserving effect but were also due to other effects called rotational effects. From the preceding quantitative considerations, it is clear that the biological nitrogen fixation (BNF) benefit of grain legumes to non-legumes due to their inclusion in a cropping system is small indeed compared to the level of N fertilizer use in the more intensive cereal production systems of the developed world but is significant at present in the context of the low input levels in subsistence farming in the tropics.\" \n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = getPrediction(to_predict['abstracts_new'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [print(predictions[i][2]) for i in range(len(predictions))];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing BERT with other text classifications "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep data for all models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is borrowed from this [link](https://towardsdatascience.com/machine-learning-nlp-text-classification-using-scikit-learn-python-and-nltk-c52b92a7c73a).\n",
    "\n",
    "Each algorithm employs a Bag of Words approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(train.text)\n",
    "# X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "# X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out [here](https://scikit-learn.org/stable/modules/naive_bayes.html#naive-bayes) for more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tfidf, train.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "text_clf = text_clf.fit(train.text, train.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "predicted = text_clf.predict(test.text)\n",
    "nb_1 = np.mean(predicted == test.sentiment)\n",
    "nb_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out [here](https://scikit-learn.org/stable/modules/svm.html) for more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "text_clf_svm = Pipeline([('vect', CountVectorizer()),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf-svm', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                                   alpha=1e-3, random_state=42)),\n",
    "])\n",
    "\n",
    "_ = text_clf_svm.fit(train.text, train.sentiment)\n",
    "\n",
    "predicted_svm = text_clf_svm.predict(test.text)\n",
    "svm_1 = np.mean(predicted_svm == test.sentiment) \n",
    "svm_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out [here](https://scikit-learn.org/stable/modules/grid_search.html#grid-search) for more detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search with Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'clf__alpha': (1e-2, 1e-3),\n",
    "}\n",
    "\n",
    "gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(train.text, train.sentiment)\n",
    "\n",
    "nb_gs = gs_clf.best_score_\n",
    "# gs_clf.best_params_\n",
    "nb_gs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search with SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_svm = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "                  'tfidf__use_idf': (True, False),\n",
    "                  'clf-svm__alpha': (1e-2, 1e-3),\n",
    "}\n",
    "gs_clf_svm = GridSearchCV(text_clf_svm, parameters_svm, n_jobs=-1)\n",
    "gs_clf_svm = gs_clf_svm.fit(train.text, train.sentiment)\n",
    "\n",
    "svm_gs = gs_clf_svm.best_score_\n",
    "# gs_clf_svm.best_params_\n",
    "svm_gs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop words, such as \"the, then, etc.\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer(stop_words='english')),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'clf__alpha': (1e-2, 1e-3),\n",
    "}\n",
    "\n",
    "gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(train.text, train.sentiment)\n",
    "\n",
    "nb_gs_rs = gs_clf.best_score_\n",
    "# gs_clf.best_params_\n",
    "nb_gs_rs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf_svm = Pipeline([('vect', CountVectorizer(stop_words='english')),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf-svm', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                                   alpha=1e-3,random_state=42)),\n",
    "])\n",
    "\n",
    "parameters_svm = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "                  'tfidf__use_idf': (True, False),\n",
    "                  'clf-svm__alpha': (1e-2, 1e-3),\n",
    "}\n",
    "\n",
    "gs_clf_svm = GridSearchCV(text_clf_svm, parameters_svm, n_jobs=-1)\n",
    "gs_clf_svm = gs_clf_svm.fit(train.text, train.sentiment)\n",
    "\n",
    "svm_gs_rs = gs_clf_svm.best_score_\n",
    "# gs_clf_svm.best_params_\n",
    "svm_gs_rs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming extracts the root word, such as changing fishing to fish. The stemmer we're using works well for English, but might throw us off for non-English. In further tuning, we should separate the non-English studies (which are few in our case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "# if you're running this for the first time, you need to download some files:\n",
    "# nltk.download()\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer('english', ignore_stopwords=True)\n",
    "\n",
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([stemmer.stem(w) for w in analyzer(doc)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('vect', StemmedCountVectorizer(stop_words='english')),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'clf__alpha': (1e-2, 1e-3),\n",
    "}\n",
    "\n",
    "gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(train.text, train.sentiment)\n",
    "\n",
    "nb_gs_stem = gs_clf.best_score_\n",
    "# gs_clf.best_params_\n",
    "nb_gs_stem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf_svm = Pipeline([('vect', StemmedCountVectorizer(stop_words='english')),\n",
    "                         ('tfidf', TfidfTransformer()),\n",
    "                         ('clf-svm', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                                   alpha=1e-3,random_state=42)),\n",
    "])\n",
    "\n",
    "parameters_svm = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "                  'tfidf__use_idf': (True, False),\n",
    "                  'clf-svm__alpha': (1e-2, 1e-3),\n",
    "}\n",
    "\n",
    "gs_clf_svm = GridSearchCV(text_clf_svm, parameters_svm, n_jobs=-1)\n",
    "gs_clf_svm = gs_clf_svm.fit(train.text, train.sentiment)\n",
    "\n",
    "svm_gs_stem = gs_clf_svm.best_score_\n",
    "# gs_clf_svm.best_params_\n",
    "svm_gs_stem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {\n",
    "    'BERT': bert_1['eval_accuracy'],\n",
    "    'Naive Bayes': nb_1,\n",
    "    'SVM': svm_1,\n",
    "    'Naive Bayes - Grid Search': nb_gs,\n",
    "    'SVM Grid Search': svm_gs,\n",
    "    'Naive Bayes - No Stop Words': nb_gs_rs,\n",
    "    'SVM - No Stop Words': svm_gs_rs,\n",
    "    'Naive Bayes - Stemming': nb_gs_stem,\n",
    "    'SVM - Stemming': svm_gs_stem,\n",
    "    'Inter-Rater (Humans agreeing with Humans)': .8\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(df.keys(), df.values()).reset_index()\n",
    "df.columns = ['value', 'metric']\n",
    "df = df.sort_values('value').reset_index()\n",
    "df['value'] = df['value'] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.barplot(x='value', y='metric', data=df, color='orange', ax=ax)\n",
    "ax.set_xlim(75, 100)\n",
    "ax.set_xlabel('\\nAccuracy (%)')\n",
    "ax.set_ylabel('')\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "plt.plot()\n",
    "plt.tight_layout()\n",
    "plt.savefig('compare_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "bert_text_classification.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "ceres_36",
   "language": "python",
   "name": "ceres_36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
